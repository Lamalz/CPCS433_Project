# -*- coding: utf-8 -*-
"""Project_SVM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13zBb-j706WjW7NPRs9c3aquOELMTlNjD

##import dependency
"""

!pip install mlxtend

# import libraries
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import plotly.express as px
from sklearn import preprocessing as perprocessing
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error as MSE
from sklearn.preprocessing import StandardScaler,RobustScaler,LabelEncoder
from sklearn.feature_selection import SelectKBest,mutual_info_regression
from sklearn.metrics import classification_report, confusion_matrix,accuracy_score
from sklearn.model_selection import GridSearchCV
from sklearn.preprocessing import OrdinalEncoder
from mlxtend.plotting import plot_decision_regions
from sklearn.svm import SVC
from sklearn.decomposition import PCA

"""## Step 1: Load the dataset

###Read the csv file
"""

#import the data
data = pd.read_csv("/content/Crop_recommendation.csv")

data.head()

"""## Step 2: Preprocess the dataset"""

#show the datatype of each feature
data.dtypes

data.isnull().sum()

"""#### Handling Categorical Variables with Label Encoding (one-hot encoding)"""

# Initialize LabelEncoder
label_encoder = LabelEncoder()

# Apply LabelEncoder to each categorical column
label_mappings = {}
for column in data.select_dtypes(include=['object']).columns:
    if column != 'label':  # Skip the target column
        data[column] = label_encoder.fit_transform(data[column])
        label_mappings[column] = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))

# Encode the target column
data['label'] = label_encoder.fit_transform(data['label'])
label_mappings['label'] = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))

# Separate features and target
X = data.drop(['label'], axis=1,inplace=False)
Y = data['label'].astype(int)

data

"""## Step3: Split the dataset"""

# Split the dataset into training and testing sets (80:20)
X,X_test,Y,Y_test=train_test_split(X,Y,test_size=0.2,random_state=42)

print("Shape of X_train :", X.shape)
print("Shape of Y_train :", Y.shape)
print("Shape of X_test :", X_test.shape)
print("Shape of Y_test :", Y_test.shape)

X

Y

"""## Step 4: Train the SVC model

After splitting the dataset, we will use the SVM model now and train it with the data
"""

modelSVM = SVC()
modelSVM.fit(X, Y)

y_predict = modelSVM.predict(X)

# Create target names from label mappings
target_names = [label for label in label_mappings['label']]

print('SVM preformance:' , classification_report(Y , y_predict,target_names=target_names))

"""## Step 5: Use grid search

Use grid search to find the best hyperparameters for the SVM model.
"""

#Create a list of hyperparameters dictionary
parameters =  [ {'kernel': ['linear','rbf'], 'C': [0.01 , 0.1 , 1 ,10 ,100 , 1000],'gamma' : [1 , 0.1 , 0.01 , 0.001 ]} ]

#calculate the grid
gridSearch = GridSearchCV(modelSVM ,parameters , refit=True , verbose=3 )

#fit the model for grid search
gridSearch.fit(X , Y)

"""Now that we used gridSearch, we will print the best parameter after the tuning"""

#print best hyperparameter after tuning
# Best parameters
best_params = gridSearch.best_params_
print(f"Best parameters: {best_params}")

# Train the best SVM model
svm_best = SVC(C=best_params['C'], gamma=best_params['gamma'], kernel=best_params['kernel'])
svm_best.fit(X, Y)

# Get the best estimator
svm_best = gridSearch.best_estimator_

# Reduce dimensions to 2D for visualization
pca = PCA(n_components=2)
X_train_2D = pca.fit_transform(X)
X_test_2D = pca.transform(X_test)

# Train SVM with best parameters on 2D data
svm_best_2D = SVC(C=svm_best.C, gamma=svm_best.gamma, kernel=svm_best.kernel)
svm_best_2D.fit(X_train_2D, Y)

# Plotting the decision boundary
plt.figure(figsize=(12, 8))
plot_decision_regions(X_train_2D, Y.values, clf=svm_best_2D, legend=2)
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.title('SVM Decision Boundary')
plt.show()

"""## Step 6: Test the performance"""

# Predict on the train set
y_pred = svm_best.predict(X)

# Evaluate the model
print("Accuracy:", accuracy_score(Y, y_pred))
print("Classification Report:")
print(classification_report(Y, y_pred,target_names=target_names))

# Confusion Matrix
conf_matrix = confusion_matrix(Y, y_pred)
print("Confusion Matrix:")
print(conf_matrix)

# Predict on the test set
y_pred = svm_best.predict(X_test)

# Evaluate the model
print("Accuracy:", accuracy_score(Y_test, y_pred))
print("Classification Report:")
print(classification_report(Y_test, y_pred,target_names=target_names))

# Confusion Matrix
conf_matrix = confusion_matrix(Y_test, y_pred)
print("Confusion Matrix:")

# Plot the confusion matrix with colors
plt.figure(figsize=(12, 10))
sns.set(font_scale=1.2)  # Adjust font size
sns.heatmap(conf_matrix, annot=True, fmt='g', cmap='Blues',xticklabels=target_names, yticklabels=target_names)  # You can adjust the colormap here
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('Confusion Matrix')
plt.show()